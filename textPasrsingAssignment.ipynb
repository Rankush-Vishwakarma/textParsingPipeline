{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz PyMuPDF python-docx openpyxl google-cloud-storage --quiet"
      ],
      "metadata": {
        "id": "Stp57jTtWsI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-beam[gcp]\n",
        "!pip install tools"
      ],
      "metadata": {
        "id": "zQasfED2Wtpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "UCJgfO-CWpS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9nCVq04Wgd6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import uuid\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from collections import Counter\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import fitz  # PyMuPDF for PDF\n",
        "from docx import Document  # python-docx for DOCX\n",
        "import xml.etree.ElementTree as ET  # For XML\n",
        "from fastapi import FastAPI, UploadFile, File, Form, HTTPException\n",
        "import requests\n",
        "from typing import Optional\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/text-parsing-pipeline-c1d668180e4f.json\"\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Configure logging\n",
        "log_file = \"pipeline_report.log\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_file),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Utility decorator for logging\n",
        "def logged(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            logger.info(f\"Started '{func.__name__}' with args: {args}, kwargs: {kwargs}\")\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"Error in '{func.__name__}': {e}\")\n",
        "            raise\n",
        "    return wrapper\n",
        "\n",
        "@logged\n",
        "def authenticate_gcs():\n",
        "    \"\"\"Authenticate with Google Cloud Storage using default credentials.\"\"\"\n",
        "    try:\n",
        "        client = storage.Client()\n",
        "        logger.info(\"GCS authentication successful\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error authenticating with GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "@logged\n",
        "def read_file_from_gcs(bucket_name, file_name):\n",
        "    \"\"\"Read a file from GCS and return its content as bytes.\"\"\"\n",
        "    client = authenticate_gcs()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.get_blob(file_name)\n",
        "    if not blob:\n",
        "        logger.error(f\"File {file_name} not found in bucket {bucket_name}\")\n",
        "        raise FileNotFoundError(f\"File {file_name} not found in bucket {bucket_name}\")\n",
        "    content = blob.download_as_bytes()\n",
        "    logger.info(f\"Successfully read {file_name} from GCS\")\n",
        "    return content\n",
        "\n",
        "@logged\n",
        "def extract_text_from_html(content):\n",
        "    \"\"\"Extract text from HTML content using BeautifulSoup.\"\"\"\n",
        "    soup = BeautifulSoup(content.decode('utf-8', errors='ignore'), 'html.parser')\n",
        "    for script_or_style in soup(['script', 'style']):\n",
        "        script_or_style.decompose()\n",
        "    text = soup.get_text(separator=' ', strip=True)\n",
        "    logger.info(f\"Extracted HTML text: {text[:50]}...\")\n",
        "    return text\n",
        "\n",
        "@logged\n",
        "def extract_text_from_pdf(file_content):\n",
        "    \"\"\"Extract text from PDF content using PyMuPDF.\"\"\"\n",
        "    with io.BytesIO(file_content) as f:\n",
        "        doc = fitz.open(stream=f, filetype=\"pdf\")\n",
        "        text = \"\\n\".join(page.get_text() for page in doc)\n",
        "        logger.info(f\"Extracted PDF text: {text[:50]}...\")\n",
        "        return text\n",
        "\n",
        "@logged\n",
        "def extract_text_from_docx(file_content):\n",
        "    \"\"\"Extract text from DOCX content using python-docx.\"\"\"\n",
        "    with io.BytesIO(file_content) as f:\n",
        "        doc = Document(f)\n",
        "        text = [para.text for para in doc.paragraphs if para.text.strip()]\n",
        "        for table in doc.tables:\n",
        "            for row in table.rows:\n",
        "                text.append(\" | \".join(cell.text.strip() for cell in row.cells))\n",
        "        text = \"\\n\".join(text)\n",
        "        logger.info(f\"Extracted DOCX text: {text[:50]}...\")\n",
        "        return text\n",
        "\n",
        "@logged\n",
        "def extract_text_from_xml(file_content):\n",
        "    \"\"\"Extract text from XML content using ElementTree.\"\"\"\n",
        "    try:\n",
        "        tree = ET.fromstring(file_content.decode('utf-8', errors='ignore'))\n",
        "        text = ' '.join(tree.itertext()).strip()\n",
        "        logger.info(f\"Extracted XML text: {text[:50]}...\")\n",
        "        return text\n",
        "    except ET.ParseError as e:\n",
        "        logger.error(f\"XML parsing error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "@logged\n",
        "def extract_text(file_content, file_name):\n",
        "    \"\"\"Extract text based on file extension.\"\"\"\n",
        "    extension = os.path.splitext(file_name)[1].lower()\n",
        "    logger.info(f\"Processing file with extension: {extension}\")\n",
        "    if extension == '.html':\n",
        "        return extract_text_from_html(file_content)\n",
        "    elif extension == '.pdf':\n",
        "        return extract_text_from_pdf(file_content)\n",
        "    elif extension in ['.docx', '.doc']:\n",
        "        return extract_text_from_docx(file_content)\n",
        "    elif extension == '.xml':\n",
        "        return extract_text_from_xml(file_content)\n",
        "    else:\n",
        "        logger.error(f\"Unsupported file type: {extension}\")\n",
        "        raise ValueError(f\"Unsupported file type: {extension}\")\n",
        "\n",
        "\n",
        "@logged\n",
        "def save_results_to_gcs(bucket_name, output_file_name, results):\n",
        "    \"\"\"Save parsed results to GCS as JSON.\"\"\"\n",
        "    client = authenticate_gcs()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(output_file_name)\n",
        "    blob.upload_from_string(json.dumps(results, indent=2), content_type='application/json')\n",
        "    logger.info(f\"Results saved to gs://{bucket_name}/{output_file_name}\")\n",
        "\n",
        "@logged\n",
        "def text_parsing_pipeline(bucket_name, input_file_name, output_file_name):\n",
        "    \"\"\"Main pipeline function to process various file types.\"\"\"\n",
        "    try:\n",
        "        file_content = read_file_from_gcs(bucket_name, input_file_name)\n",
        "        text = extract_text(file_content, input_file_name)\n",
        "        save_results_to_gcs(bucket_name, output_file_name, text)\n",
        "        logger.info(f\"Pipeline completed for {input_file_name}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Pipeline error: {e}\")\n",
        "        raise\n",
        "\n",
        "# FastAPI app\n",
        "app = FastAPI(title='app')\n",
        "GCS_BUCKET = \"text-pipeline-bucket-rankush\"\n",
        "GCS_FOLDER = \"input\"\n",
        "SUPPORTED_TYPES = ['pdf','docx','xlsx','html']\n",
        "def upload_to_gcs(file_path: Optional[str] = None, url: Optional[str] = None) -> tuple:\n",
        "    \"\"\"Upload file or URL content to GCS and return paths\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    filename = str(uuid.uuid4())\n",
        "    blob_path = f\"{GCS_FOLDER}/{filename}\"\n",
        "    ext = None\n",
        "    inputPath = ''\n",
        "    outputPath = ''\n",
        "    try:\n",
        "        if file_path:\n",
        "            ext = os.path.splitext(file_path)[1].lower().lstrip('.')\n",
        "            if ext not in SUPPORTED_TYPES:\n",
        "                raise ValueError(f\"Unsupported file type: {ext}\")\n",
        "\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                content = f.read()\n",
        "\n",
        "            blob = storage_client.bucket(GCS_BUCKET).blob(f\"{blob_path}.{ext}\")\n",
        "            blob.upload_from_string(content)\n",
        "            logger.info(f\"Uploaded file to gs://{GCS_BUCKET}/{blob_path}.{ext}\")\n",
        "            inputPath = f\"{blob_path}.{ext}\"\n",
        "        elif url:\n",
        "            ext = \"html\"\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            blob = storage_client.bucket(GCS_BUCKET).blob(f\"{blob_path}.{ext}\")\n",
        "            blob.upload_from_string(response.text, content_type=\"text/html\")\n",
        "            logger.info(f\"Uploaded URL content to gs://{GCS_BUCKET}/{blob_path}.{ext}\")\n",
        "            inputPath = f\"{blob_path}.{ext}\"\n",
        "\n",
        "        input_gcs_path = f\"gs://{GCS_BUCKET}/{blob_path}.{ext}\"\n",
        "        output_gcs_path = f\"gs://{GCS_BUCKET}/output/{filename}.json\"\n",
        "        outputPath = f\"output/{filename}.json\"\n",
        "\n",
        "        return inputPath, outputPath\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Upload failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def run_pipeline_externally(input_path: str, output_path: str):\n",
        "    \"\"\"Execute the processing pipeline\"\"\"\n",
        "    # Import your actual pipeline function here\n",
        "    logger.info(f\"Starting pipeline for {input_path}\")\n",
        "    try:\n",
        "        result = text_parsing_pipeline(\n",
        "            GCS_BUCKET,\n",
        "            input_path,\n",
        "            output_path\n",
        "        )\n",
        "        logger.info(\"Pipeline completed successfully\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "input_path, output_path = upload_to_gcs(url = 'https://www.geeksforgeeks.org/python/convert-mp3-to-wav-using-python/')\n",
        "run_pipeline_externally(input_path, output_path)"
      ]
    }
  ]
}